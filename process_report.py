import os
import glob
import json
import re
import shutil
from pdf2image import convert_from_path
import cv2
import numpy as np
from paddleocr import PaddleOCR

# Configuration
LABEL_KEYS = {
    "Detrusor instability": "Detrusor_instability",
    "Flow pattern": "Flow_pattern",
    "EMG: ES relaxation": "EMG_ES_relaxation",
    "Trabeculation": "Trabeculation",
    "Diverticulum": "Diverticulum",
    "Cystocele": "Cystocele",
    "VUR": "VUR",
    "Bladder neck relaxation": "Bladder_neck_relaxation",
    "External sphincter relaxation": "External_sphincter_relaxation",
    "Pelvic floor relaxation": "Pelvic_floor_relaxation"
}

VALUE_MAP = {
    "Yes": "1", "No": "0", "Obstruction": "0", "Intermittent": "1",
    "Interrupted": "2", "Staccato": "3", "Supervoider": "4", "Bell": "5",
    "Fair": "0", "Acceptable": "1", "Impaired": "2", "Poor": "3",
    "Artifect": "4", "Delayed": "4", "Inconclusive": "5"
}

# Load offset configuration
with open("offset_config.json", "r", encoding="utf-8") as f:
    OFFSET_CFG = json.load(f)

# Initialize OCR once
ocr = PaddleOCR(use_angle_cls=True, lang='en', show_log=False)


def is_checked_pixel(b, g, r):
    """
    Âà§Êñ∑ÂñÆ‰∏ÄÂÉèÁ¥†ÊòØÂê¶ÁÇ∫ÂãæÈÅ∏Ê®ôË®òÔºàÊ©òËâ≤Ê°ÜÔºâ
    """
    return 240 <= b <= 255 and 80 <= g <= 150 and r <= 40


def is_checked_region(img, x, y, delta=15):
    """
    Âú® (x,y) Âë®Âúç delta ÂçäÂæëÂÖßËã•Êúâ‰ªª‰∏ÄÂãæÈÅ∏ÂÉèÁ¥†Âç≥ÂõûÂÇ≥ True
    """
    h, w = img.shape[:2]
    for dx in range(-delta, delta+1):
        for dy in range(-delta, delta+1):
            px, py = x + dx, y + dy
            if 0 <= px < w and 0 <= py < h and is_checked_pixel(*img[py, px]):
                return True
    return False


def visualize_detected_labels(img, ocr_results, annotated_dir, page_idx):
    """
    Ê®ôË®ª OCR ÂÅµÊ∏¨ÁµêÊûúËàá checkbox ÁãÄÊÖãÔºå‰∏¶Â≠òËá≥ annotated_dir
    """
    debug_img = img.copy()
    for line in ocr_results[0]:
        coords, (text, _) = line
        txt = text.strip()
        for key in LABEL_KEYS:
            if key in txt:
                print(f"\nüü© Detected Label '{key}' at {coords[0]}")
                pts = np.array(coords, np.int32)
                cv2.polylines(debug_img, [pts], True, (0,255,0), 2)
                x0, y0 = map(int, coords[0])
                for opt in OFFSET_CFG[key]:
                    px, py = x0 + opt['offset'][0], y0 + opt['offset'][1]
                    checked = is_checked_region(img, px, py)
                    mapped = VALUE_MAP.get(opt['label'], 'Unknown')
                    print(f"  ‚Üí Checking '{opt['label']}' at ({px},{py}) ‚Üí {'‚úî' if checked else '‚úò'} mapped '{mapped}'")
                    cv2.circle(debug_img, (px, py), 5, (0,0,255) if checked else (255,0,0), -1)
    os.makedirs(annotated_dir, exist_ok=True)
    out_path = os.path.join(annotated_dir, f"annotated_page_{page_idx}.jpg")
    cv2.imwrite(out_path, debug_img)


def extract_labels_from_image(img, ocr_results):
    """
    Ê†πÊìö OCR ÁµêÊûúËàá OFFSET_CFGÔºåÂõûÂÇ≥ÂñÆÂºµÂΩ±ÂÉè‰∏≠ÊâÄÊúâ label ÁöÑÂÄº
    """
    data = {}  # ÊîπÁÇ∫Á©∫Â≠óÂÖ∏Ôºå‰∏çÈ†êË®≠ 'NA'
    for line in ocr_results[0]:
        coords, (text, _) = line
        txt = text.strip()
        for key_text, key_label in LABEL_KEYS.items():
            if key_text in txt:
                # Â¶ÇÊûúÈÄôÂÄãÊ®ôÁ±§Â∑≤Á∂ìÊúâÂÄºÔºåË∑≥ÈÅé
                if key_label in data:
                    continue
                    
                x0, y0 = map(int, coords[0])
                picks = []
                for opt in OFFSET_CFG[key_text]:
                    px, py = x0 + opt['offset'][0], y0 + opt['offset'][1]
                    if 0 <= px < img.shape[1] and 0 <= py < img.shape[0] and is_checked_region(img, px, py):
                        picks.append(VALUE_MAP.get(opt['label']))
                if picks:
                    unique = sorted(set(picks))
                    data[key_label] = ','.join(unique)
                else:
                    data[key_label] = 'NA'
                break
    return data


def process_report_folder(report_dir):
    """
    ËôïÁêÜÂñÆ‰ªΩÂ†±Âëä PDFÔºö
      - convert_from_path ËΩâ JPG
      - OCR ËàáÊ®ôË®ª
      - ÊäΩÂèñ checkbox ÁµêÊûú
      - ÊúÄÁµÇ output.txt Â≠òËá≥ output/result
    """
    annotated_dir = os.path.join(report_dir, 'output', 'annotated')
    result_dir    = os.path.join(report_dir, 'output', 'result')
    os.makedirs(annotated_dir, exist_ok=True)
    os.makedirs(result_dir,    exist_ok=True)

    # ÂàùÂßãÂåñË≥áÊñôÂ≠óÂÖ∏Âíå Flow_pattern Ë®àÊï∏Âô®
    all_data = {v: 'NA' for v in LABEL_KEYS.values()}
    flow_pattern_count = 0  # ËøΩËπ§ Flow_pattern Âá∫ÁèæÊ¨°Êï∏

    for fname in sorted(os.listdir(report_dir)):
        if not fname.lower().endswith('.pdf'):
            continue
        pdf_path = os.path.join(report_dir, fname)
        pages = convert_from_path(pdf_path, dpi=300)
        for i, page in enumerate(pages):
            img = cv2.cvtColor(np.array(page), cv2.COLOR_RGB2BGR)
            res = ocr.ocr(img, cls=True)
            visualize_detected_labels(img, res, annotated_dir, i)
            data = extract_labels_from_image(img, res)
            
            # ËôïÁêÜÊØèÂÄãÊ®ôÁ±§
            for k, v in data.items():
                # ÁâπÊÆäËôïÁêÜ Flow_pattern
                if k == 'Flow_pattern':
                    flow_pattern_count += 1
                    # Âè™Âú®Á¨¨‰∫åÊ¨°Âá∫ÁèæÊôÇÊõ¥Êñ∞ÂÄº
                    if flow_pattern_count == 2:
                        all_data[k] = v
                # ÂÖ∂‰ªñÊ®ôÁ±§ÔºöÂè™Âú®Á¨¨‰∏ÄÊ¨°Âá∫ÁèæÊôÇÊõ¥Êñ∞
                elif all_data[k] == 'NA':
                    all_data[k] = v

    out_path = os.path.join(result_dir, 'output.txt')
    with open(out_path, 'w', encoding='utf-8') as f:
        for section in [
            ['Detrusor_instability'],
            ['Flow_pattern', 'EMG_ES_relaxation'],
            ['Trabeculation', 'Diverticulum', 'Cystocele', 'VUR',
             'Bladder_neck_relaxation', 'External_sphincter_relaxation', 'Pelvic_floor_relaxation']
        ]:
            for key in section:
                f.write(f"{key}: {all_data[key]}\n")
            f.write("\n")
    print(f"‚úÖ Results saved: {out_path}")


def batch_process_reports(root_dir='raw_dataset', log_path='report_extraction_log.json'):
    """
    ÊâπÊ¨°ËôïÁêÜ raw_dataset ÂÖßÊâÄÊúâ patient/reportÔºåË™øÁî® process_report_folder„ÄÇ
    ‰∏¶Ë®òÈåÑÊØèÂÄã report_dir ÁãÄÊÖãÊñº log_path„ÄÇ
    """
    if os.path.exists(log_path):
        with open(log_path, 'r', encoding='utf-8') as f:
            log = json.load(f)
    else:
        log = {}

    total_new = 0
    for patient_id in sorted(os.listdir(root_dir)):
        patient_dir = os.path.join(root_dir, patient_id)
        if not os.path.isdir(patient_dir):
            continue

        # Êñ∞Â¢ûÔºöËã• patient_dir Â∫ï‰∏ãÁõ¥Êé•Êúâ PDFÔºå‰πüË®òÈåÑ‰∏ã‰æÜÔºà‰ΩÜ‰ªç‰ª•Â≠êË≥áÊñôÂ§æÁÇ∫ÂñÆ‰ΩçËôïÁêÜÔºâ
        # ÈÄôË£°ÂÉÖÂëàÁèæÊúâÈúÄÊôÇÂèØÂàóÂç∞ÔºåÂØ¶ÈöõËôïÁêÜÂú®Â≠êË≥áÊñôÂ§æË§áË£ΩÊôÇ‰∏Ä‰ΩµËôïÁêÜ

        for report_id in sorted(os.listdir(patient_dir)):
            report_dir = os.path.join(patient_dir, report_id)
            if not os.path.isdir(report_dir):
                continue

            # ‚Äî‚Äî Êñ∞Â¢ûÔºöÂæû report_id Âèñ YYYYMMDDÔºåÂõû‰∏ä‰∏ÄÂ±§Êâæ PDFÔºåË§áË£ΩÂà∞Â≠êË≥áÊñôÂ§æ ‚Äî‚Äî 
            m = re.search(r'-(\d{8})$', report_id)
            if m:
                date_str = m.group(1)
                candidate_pdf = os.path.join(patient_dir, f"{date_str}Â†±Âëä.pdf")
                if os.path.isfile(candidate_pdf):
                    dest_pdf = os.path.join(report_dir, f"{date_str}Â†±Âëä.pdf")
                    if not os.path.isfile(dest_pdf):
                        print(f"üìÑ Found {candidate_pdf}, copying into {report_dir}")
                        shutil.copy2(candidate_pdf, dest_pdf)
            # ‚Äî‚Äî Êñ∞Â¢ûÁµêÊùü ‚Äî‚Äî 

            status = log.get(report_dir)
            if status == 'done':
                print(f"‚úÖ Skipped (done): {report_dir}")
                continue

            pdfs = glob.glob(os.path.join(report_dir, '*.pdf'))
            if not pdfs:
                print(f"‚ö†Ô∏è  No PDF in: {report_dir}")
                log[report_dir] = 'no_pdfs'
                continue

            print(f"üü° Processing: {report_dir}")
            try:
                process_report_folder(report_dir)
                log[report_dir] = 'done'
                total_new += 1
            except Exception as e:
                print(f"‚ùå Error processing {report_dir}: {e}")
                log[report_dir] = 'error'

            # ÊØèËôïÁêÜÂÆå‰∏ÄÂÄãÂ∞±Á´ãÂç≥Â≠ò logÔºåÈò≤Ê≠¢‰∏≠Êñ∑
            with open(log_path, 'w', encoding='utf-8') as f:
                json.dump(log, f, ensure_ascii=False, indent=2)

    print(f"\nüèÅ Batch complete. New processed: {total_new}")
    with open(log_path, 'w', encoding='utf-8') as f:
        json.dump(log, f, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    # ÈªòË™ç‰ª•ÂëΩ‰ª§ÂàóÂèÉÊï∏ÂëºÂè´ batch_process_reports
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--root_dir', type=str, default='../../raw_dataset', help='raw_dataset Ê†πÁõÆÈåÑ')
    parser.add_argument('--log_path', type=str, default='../../report_extraction_log.json', help='ËôïÁêÜ log Ê™î')
    args = parser.parse_args()
    batch_process_reports(root_dir=args.root_dir, log_path=args.log_path)
